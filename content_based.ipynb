{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e593924-243a-46e1-a2d2-00c95be714f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_8636\\4134195364.py:16: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  news_df = pd.read_csv(file_path, sep='\\t', header=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Category-only Content-Based =====\n",
      "Category Only -> AUC: 0.7679, nDCG@5: 0.0441, Precision@5: 0.0179, Recall@5: 0.0536, HitRate@5: 0.0300\n",
      "\n",
      "===== Category + Entity Content-Based =====\n",
      "Category + Entity -> AUC: 0.7781, nDCG@5: 0.0445, Precision@5: 0.0143, Recall@5: 0.0446, HitRate@5: 0.0300\n",
      "\n",
      "Non-zero entity vectors: 36210 / 51282\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, ndcg_score\n",
    "from numpy.linalg import norm\n",
    "import json\n",
    "\n",
    "# Load behaviors.tsv\n",
    "def load_behaviors_sample(file_path, sample_frac=0.1, random_state=None):\n",
    "    behaviors = pd.read_csv(file_path, sep='\\t', header=None,\n",
    "                            names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n",
    "    behaviors_sample = behaviors.sample(frac=sample_frac, random_state=random_state).reset_index(drop=True)\n",
    "    return behaviors_sample\n",
    "\n",
    "# Load news.tsv\n",
    "def load_news(file_path):\n",
    "    news_df = pd.read_csv(file_path, sep='\\t', header=None,\n",
    "                          names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'Entity'],\n",
    "                          index_col=False)\n",
    "    return news_df\n",
    "\n",
    "# build interaction matrix\n",
    "def build_interaction_matrix(behaviors):\n",
    "    user_item_pairs = []\n",
    "    for _, row in behaviors.iterrows():\n",
    "        user = row['UserID']\n",
    "        impressions = row['Impressions'].split()\n",
    "        for imp in impressions:\n",
    "            news_id, label = imp.split('-')\n",
    "            user_item_pairs.append((user, news_id, int(label)))\n",
    "    interaction_df = pd.DataFrame(user_item_pairs, columns=['UserID', 'NewsID', 'Label'])\n",
    "    return interaction_df\n",
    "\n",
    "# Load entity embedding\n",
    "def load_entity_embeddings(file_path):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            key = parts[0]\n",
    "            vec = np.array([float(x) for x in parts[1:]])\n",
    "            embeddings[key] = vec\n",
    "    return embeddings\n",
    "\n",
    "# computer entity vector\n",
    "def compute_news_entity_vectors(news_df, entity_embeddings):\n",
    "    news_entity_vecs = {}\n",
    "    for row in news_df.itertuples():\n",
    "        if pd.notna(row.Entity):\n",
    "            try:\n",
    "                entity_info_list = json.loads(row.Entity.replace(\"'\", '\"')) \n",
    "                wikidata_ids = [entity['WikidataId'] for entity in entity_info_list if 'WikidataId' in entity]\n",
    "            except Exception as e:\n",
    "                wikidata_ids = []\n",
    "        else:\n",
    "            wikidata_ids = []\n",
    "\n",
    "        vecs = [entity_embeddings[eid] for eid in wikidata_ids if eid in entity_embeddings]\n",
    "        if vecs:\n",
    "            mean_vec = np.mean(vecs, axis=0)\n",
    "            news_entity_vecs[row.NewsID] = mean_vec\n",
    "        else:\n",
    "            news_entity_vecs[row.NewsID] = np.zeros_like(next(iter(entity_embeddings.values())))\n",
    "    return news_entity_vecs, len(next(iter(entity_embeddings.values())))\n",
    "\n",
    "\n",
    "# category One-Hot encoding\n",
    "def encode_news_category(news_df):\n",
    "    categories = pd.get_dummies(news_df['Category'])\n",
    "    categories.index = news_df['NewsID']\n",
    "    news_category_map = {news_id: categories.loc[news_id].values for news_id in news_df['NewsID']}\n",
    "    return news_category_map, categories.shape[1]\n",
    "\n",
    "# concatenate entity and category features\n",
    "def combine_news_features(news_entity_vecs, news_category_map):\n",
    "    combined_vectors = {}\n",
    "    for news_id in news_entity_vecs:\n",
    "        entity_vec = news_entity_vecs[news_id]\n",
    "        category_vec = news_category_map.get(news_id, np.zeros(len(next(iter(news_category_map.values())))))\n",
    "        combined_vectors[news_id] = np.concatenate([entity_vec, category_vec])\n",
    "    return combined_vectors\n",
    "\n",
    "# build user interest vectors\n",
    "def build_user_profiles(interaction_df, news_vectors):\n",
    "    user_profiles = {}\n",
    "    for user_id, group in interaction_df[interaction_df['Label'] == 1].groupby('UserID'):\n",
    "        clicked_news_ids = group['NewsID']\n",
    "        clicked_vecs = [news_vectors[nid] for nid in clicked_news_ids if nid in news_vectors]\n",
    "        if clicked_vecs:\n",
    "            user_profiles[user_id] = np.mean(clicked_vecs, axis=0)\n",
    "        else:\n",
    "            user_profiles[user_id] = np.zeros_like(next(iter(news_vectors.values())))\n",
    "    return user_profiles\n",
    "\n",
    "# computer cosin similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
    "        return 0.0\n",
    "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "# Evaluate with additional metrics\n",
    "def evaluate_content_based(interaction_df, user_profiles, news_vectors, k=5, sample_size=100):\n",
    "    np.random.seed(42)\n",
    "    all_users = list(user_profiles.keys())\n",
    "    sampled_users = np.random.choice(all_users, size=min(sample_size, len(all_users)), replace=False)\n",
    "    \n",
    "    y_true_all = []\n",
    "    y_score_all = []\n",
    "    ndcg_values = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    hitrate_count = 0\n",
    "\n",
    "    for user in sampled_users:\n",
    "        user_data = interaction_df[interaction_df['UserID'] == user]\n",
    "        true_labels = []\n",
    "        pred_scores = []\n",
    "        user_vec = user_profiles[user]\n",
    "        positive_news = set(user_data[user_data['Label'] == 1]['NewsID'])\n",
    "\n",
    "        for row in user_data.itertuples():\n",
    "            if row.NewsID not in news_vectors:\n",
    "                continue\n",
    "            news_vec = news_vectors[row.NewsID]\n",
    "            pred = cosine_similarity(user_vec, news_vec)\n",
    "            true_labels.append(row.Label)\n",
    "            pred_scores.append(pred)\n",
    "            y_true_all.append(row.Label)\n",
    "            y_score_all.append(pred)\n",
    "\n",
    "        if len(true_labels) > 1:\n",
    "            ndcg = ndcg_score([true_labels], [pred_scores], k=k)\n",
    "            ndcg_values.append(ndcg)\n",
    "\n",
    "            # Precision, Recall, HitRate\n",
    "            sorted_indices = np.argsort(pred_scores)[::-1][:k]\n",
    "            recommended_top_k = [user_data.iloc[i].NewsID for i in sorted_indices]\n",
    "            hit_count = len(set(recommended_top_k).intersection(positive_news))\n",
    "\n",
    "            precision_list.append(hit_count / k)\n",
    "            recall_list.append(hit_count / len(positive_news) if positive_news else 0)\n",
    "            if hit_count > 0:\n",
    "                hitrate_count += 1\n",
    "\n",
    "    auc = roc_auc_score(y_true_all, y_score_all)\n",
    "    mean_ndcg = np.mean(ndcg_values)\n",
    "    mean_precision = np.mean(precision_list)\n",
    "    mean_recall = np.mean(recall_list)\n",
    "    hitrate = hitrate_count / len(sampled_users)\n",
    "\n",
    "    return auc, mean_ndcg, mean_precision, mean_recall, hitrate\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load data\n",
    "    behaviors = load_behaviors_sample('MINDsmall_train/behaviors.tsv', sample_frac=1)\n",
    "    news_df = load_news('MINDsmall_train/news.tsv')\n",
    "    interaction_df = build_interaction_matrix(behaviors)\n",
    "\n",
    "    # Split train/test\n",
    "    train_df = interaction_df.sample(frac=0.8, random_state=42)\n",
    "    test_df = interaction_df.drop(train_df.index)\n",
    "\n",
    "    # Entity embeddings\n",
    "    entity_embeddings = load_entity_embeddings('MINDsmall_train/entity_embedding.vec')\n",
    "    news_entity_vecs, entity_dim = compute_news_entity_vectors(news_df, entity_embeddings)\n",
    "\n",
    "    # Category features\n",
    "    news_category_map, category_dim = encode_news_category(news_df)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Category-only Features\n",
    "    # -------------------------------\n",
    "    print(\"\\n===== Category-only Content-Based =====\")\n",
    "    category_only_profiles = build_user_profiles(train_df, news_category_map)\n",
    "    auc_category, ndcg_category, precision_category, recall_category, hitrate_category = evaluate_content_based(\n",
    "        test_df_sampled, category_only_profiles, news_category_map)\n",
    "\n",
    "    print(f\"Category Only -> AUC: {auc_category:.4f}, nDCG@5: {ndcg_category:.4f}, Precision@5: {precision_category:.4f}, Recall@5: {recall_category:.4f}, HitRate@5: {hitrate_category:.4f}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. Category + Entity Features\n",
    "    # -------------------------------\n",
    "    print(\"\\n===== Category + Entity Content-Based =====\")\n",
    "    combined_vectors = combine_news_features(news_entity_vecs, news_category_map)\n",
    "    combined_profiles = build_user_profiles(train_df, combined_vectors)\n",
    "    auc_combined, ndcg_combined, precision_combined, recall_combined, hitrate_combined = evaluate_content_based(\n",
    "        test_df_sampled, combined_profiles, combined_vectors)\n",
    "\n",
    "    print(f\"Category + Entity -> AUC: {auc_combined:.4f}, nDCG@5: {ndcg_combined:.4f}, Precision@5: {precision_combined:.4f}, Recall@5: {recall_combined:.4f}, HitRate@5: {hitrate_combined:.4f}\")\n",
    "\n",
    "    # Entity vector sparsity check\n",
    "    non_zero_vec_count = sum(1 for vec in news_entity_vecs.values() if not np.all(vec == 0))\n",
    "    print(f\"\\nNon-zero entity vectors: {non_zero_vec_count} / {len(news_entity_vecs)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3917b2d2-62eb-45f0-8665-1053c9c8c50f",
   "metadata": {},
   "source": [
    "# Analysis and Conclusion\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation Metrics\n",
    "\n",
    "| Model                        | AUC    | nDCG@5 | Precision@5 | Recall@5 | HitRate@5 |\n",
    "|------------------------------|--------|--------|--------------|-----------|------------|\n",
    "| Category Only                | 0.7679 | 0.0441 | 0.0179       | 0.0536    | 0.0300     |\n",
    "| Category + Entity            | 0.7781 | 0.0445 | 0.0143       | 0.0446    | 0.0300     |\n",
    "| Entity Coverage              | -      | -      | -            | -         | 36210 / 51282 (70.6%) |\n",
    "\n",
    "---\n",
    "\n",
    "## Analysis\n",
    "\n",
    "### AUC\n",
    "- Both models show good overall ranking ability.\n",
    "- Category + Entity slightly outperforms Category Only.\n",
    "\n",
    "### nDCG@5\n",
    "- Both models achieve similar nDCG@5 around 0.044.\n",
    "- Indicates limited effectiveness in top-5 recommendation quality.\n",
    "\n",
    "### Precision@5 and Recall@5\n",
    "- Precision is low for both models, between 1.4% and 1.8%.\n",
    "- Recall is slightly higher for Category Only.\n",
    "\n",
    "### HitRate@5\n",
    "- About 3% of users received at least one correct recommendation.\n",
    "- HitRate is the same for both models.\n",
    "\n",
    "### Entity Coverage\n",
    "- 70.6% of news items have valid entity vectors.\n",
    "- Entity vectors contribute to AUC improvement but have minimal effect on top-k metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "1. Content-Based models significantly outperform User-Based models in ranking capability (AUC > 0.77 vs. 0.5).\n",
    "2. Top-k recommendation effectiveness remains low.\n",
    "3. Entity embeddings improve AUC but do not significantly enhance precision or recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec8103-3930-4270-a9b6-a802ee0f0c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
